{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lolu-U/Collab-LLM/blob/main/oobabooga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d94969e-dee6-4a19-804d-c18fb1ca81ca",
      "metadata": {
        "id": "2d94969e-dee6-4a19-804d-c18fb1ca81ca"
      },
      "source": [
        "<!-- Banner Image -->\n",
        "<img src=\"https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brev-xmas-3.png\" width=\"100%\">\n",
        "\n",
        "<!-- Links -->\n",
        "<center>\n",
        "  <a href=\"https://console.brev.dev\" style=\"color: #06b6d4;\">Console</a> â€¢\n",
        "  <a href=\"https://brev.dev\" style=\"color: #06b6d4;\">Docs</a> â€¢\n",
        "  <a href=\"/\" style=\"color: #06b6d4;\">Templates</a> â€¢\n",
        "  <a href=\"https://discord.gg/NVDyv7TUgJ\" style=\"color: #06b6d4;\">Discord</a>\n",
        "</center>\n",
        "\n",
        "# Run Oobabooga, the LLM WebUI ðŸ¤™\n",
        "\n",
        "Welcome!\n",
        "\n",
        "In this notebook, we will run the LLM WebUI, Oobabooga. This UI lets you play around with large language models / text generatation without needing any code!\n",
        "\n",
        "### Help us make this tutorial better! Please provide feedback on the [Discord channel](https://discord.gg/T9bUNqMS8d) or on [X](https://x.com/harperscarroll).\n",
        "\n",
        "A note about running Jupyter Notebooks: Press Shift + Enter to run a cell. A * in the left-hand cell box means the cell is running. A number means it has completed. If your Notebook is acting weird, you can interrupt a too-long process by interrupting the kernel (Kernel tab -> Interrupt Kernel) or even restarting the kernel (Kernel tab -> Restart Kernel). Note restarting the kernel will require you to run everything from the beginning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1f7263-95bb-4ac0-90bd-a3cf3dbced2c",
      "metadata": {
        "id": "ae1f7263-95bb-4ac0-90bd-a3cf3dbced2c"
      },
      "source": [
        "## Let's begin!\n",
        "\n",
        "I used a GPU from [brev.dev](https://brev.dev). I used an A10G, with 24GB GPU Memory, 16 GB RAM, 120 GB storage. This machine is about $1/hr.\n",
        "\n",
        "Click the badge below to get your preconfigured instance:\n",
        "\n",
        "[![ Click here to deploy.](https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brevdeploynavy.svg)](https://console.brev.dev/environment/new?instance=A10G:g5.xlarge&diskStorage=120&name=oobabooga&file=https://github.com/brevdev/notebooks/raw/main/oobabooga.ipynb&python=3.10&cuda=12.0.1)\n",
        "\n",
        "Once you've checked out your machine and landed in your instance page, select the specs you'd like (I used **Python 3.10 and CUDA 12.0.1**; these should be preconfigured for you if you use the badge above) and click the \"Build\" button to build your verb container. Give this a few minutes.\n",
        "\n",
        "A few minutes after your model has started Running, click the 'Notebook' button on the top right of your screen once it illuminates (you may need to refresh the screen). You will be taken to a Jupyter Lab environment, where you can upload this Notebook.\n",
        "\n",
        "Note: You can connect your cloud credits (AWS or GCP) by clicking \"Org: \" on the top right, and in the panel that slides over, click \"Connect AWS\" or \"Connect GCP\" under \"Connect your cloud\" and follow the instructions linked to attach your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e034265-b6e3-4974-b190-84a3c99279cb",
      "metadata": {
        "id": "3e034265-b6e3-4974-b190-84a3c99279cb",
        "outputId": "3b5cbbe7-feaf-4539-fef2-0334a45db4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'text-generation-webui'...\n",
            "remote: Enumerating objects: 14265, done.\u001b[K\n",
            "remote: Counting objects: 100% (1716/1716), done.\u001b[K\n",
            "remote: Compressing objects: 100% (261/261), done.\u001b[K\n",
            "remote: Total 14265 (delta 1553), reused 1552 (delta 1455), pack-reused 12549\u001b[K\n",
            "Receiving objects: 100% (14265/14265), 24.33 MiB | 61.06 MiB/s, done.\n",
            "Resolving deltas: 100% (9879/9879), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oobabooga/text-generation-webui.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af22f0ee-89dd-41b4-95c8-e965c039edd3",
      "metadata": {
        "id": "af22f0ee-89dd-41b4-95c8-e965c039edd3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('text-generation-webui')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24190e51-7295-44a6-9d7c-a560bde1811b",
      "metadata": {
        "id": "24190e51-7295-44a6-9d7c-a560bde1811b",
        "outputId": "066f942f-330a-4c20-bd38-1ffb1974dee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 https://ngrok-agent.s3.amazonaws.com buster InRelease\n",
            "Fetched 110 kB in 0s (245 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "expect is already the newest version (5.45.4-2build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y -q\n",
        "!sudo apt-get install expect -y -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b9f66a-acd4-4b31-a498-7cd5aabaf08e",
      "metadata": {
        "id": "e1b9f66a-acd4-4b31-a498-7cd5aabaf08e",
        "outputId": "138ce935-9adb-4692-ae36-f4eae6609bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing oobabooga_start.expect\n"
          ]
        }
      ],
      "source": [
        "%%writefile oobabooga_start.expect\n",
        "#!/usr/bin/expect\n",
        "\n",
        "spawn ./start_linux.sh --share\n",
        "expect \"What is your GPU?\"\n",
        "send \"A\\r\"\n",
        "expect \"Do you want to use CUDA 11.8 instead of 12.1?\"\n",
        "send \"N\\r\"\n",
        "interact"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e314c64-b416-4698-aa80-96a59c7cad51",
      "metadata": {
        "id": "8e314c64-b416-4698-aa80-96a59c7cad51"
      },
      "source": [
        "### Run Oobabooga + Download Models\n",
        "\n",
        "Run the code below to get a **public URL** for your Oobabooga session. Let it run until the output stops and you see something like this:\n",
        "\n",
        "![image.png](attachment:266a2e1c-b76b-4df9-a292-9d9921372e9f.png)\n",
        "\n",
        "There is no more code after the code cell below, as the output will get long and hard to follow once you start working in Oobabooga.\n",
        "\n",
        "***If you prefer to not expose your session on a URL:*** remove the `--share` parameter from the `whisper_start.expect` file above and re-run the cell. Then, on a terminal on your LOCAL machine (i.e. NOT from within this machine/notebook, but on your laptop), run `brev port-forward oobabooga -p 7860:7860`. If you chose a different machine name, replace `oobabooga` with that name. Then, open a browser, and search `localhost:7860`; this should open to the Oobabooga UI.\n",
        "\n",
        "#### To download a model, follow the steps here:\n",
        "\n",
        "[![Download a Model to Oobabooga](https://cdn.loom.com/sessions/thumbnails/02da582d0ed34a19ab26cd3955acb6dc-with-play.gif)](https://www.loom.com/share/02da582d0ed34a19ab26cd3955acb6dc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9820e848-4f02-4bba-98c8-e66ae3c4b7f1",
      "metadata": {
        "id": "9820e848-4f02-4bba-98c8-e66ae3c4b7f1"
      },
      "outputs": [],
      "source": [
        "!chmod +x oobabooga_start.expect\n",
        "!sudo ./oobabooga_start.expect"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}